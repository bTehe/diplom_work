{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d489a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Type, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, ReLU,\n",
    "    MaxPooling1D, Dropout, Bidirectional, LSTM,\n",
    "    Dense, Multiply, Softmax, Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, matthews_corrcoef,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24a973",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../NN Datasets/x_train.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m y_train = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../NN Datasets/y_train.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m X_train = X_train.drop([ X_train.columns[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mInit_Win_bytes_forward\u001b[39m\u001b[33m\"\u001b[39m ], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dubst\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dubst\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dubst\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dubst\\miniconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:2053\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:331\u001b[39m, in \u001b[36mgetstate\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Шляхи до даних\n",
    "DATA_DIR = Path(\"../NN Datasets\")\n",
    "RESULTS_PATH = Path(\"grid_search_val_test_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643447af",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 20\n",
    "NUM_FEATURES = 34  # кількість ознак у X\n",
    "NUM_CLASSES = 7    # кількість класів для класифікації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f4e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 5, 4, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAM_GRID: Dict[str, List[Any]] = {\n",
    "    'filters': [32, 64, 128],\n",
    "    'kernel_size': [3, 5, 7],\n",
    "    'pool_size': [2, 3],\n",
    "    'lstm_units': [64, 128, 256],\n",
    "    'lstm_layers': [1, 2],\n",
    "    'dropout_rate': [0.2, 0.3, 0.5],\n",
    "    'recurrent_dropout': [0.1, 0.2],\n",
    "    'activation': ['relu', 'selu'],\n",
    "    'kernel_initializer': ['he_uniform', 'glorot_uniform'],\n",
    "    'optimizer': [Adam, RMSprop],\n",
    "    'optimizer__learning_rate': [1e-2, 1e-3, 1e-4],\n",
    "    'batch_size': [64, 128, 256],\n",
    "    'epochs': [10, 20, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CALLBACKS = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c07ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "– Обрізаю 8 рядків (залишаю 11878320 для 593916 вікон)\n",
      "– Обрізаю 5 рядків (залишаю 287580 для 14379 вікон)\n",
      "– Обрізаю 18 рядків (залишаю 422900 для 21145 вікон)\n"
     ]
    }
   ],
   "source": [
    "def load_csv(path: Path, drop_cols: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Завантажує CSV у DataFrame та видаляє непотрібні стовпці.\n",
    "\n",
    "    :param path: шлях до файлу CSV\n",
    "    :param drop_cols: список назв колонок для видалення\n",
    "    :return: очищений DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68002f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (593916, 20, 34)\n",
      "X_val: (14379, 20, 34)\n",
      "X_test: (21145, 20, 34)\n"
     ]
    }
   ],
   "source": [
    "def prepare_windowed_data(\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.DataFrame,\n",
    "    window_size: int,\n",
    "    num_classes: int\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Розбиває послідовність на вікна фіксованого розміру і повертає X у форматі\n",
    "    (num_windows, window_size, num_features) та one-hot закодовані мітки за останній\n",
    "    елемент кожного вікна.\n",
    "    \"\"\"\n",
    "    X_arr = X.values\n",
    "    y_arr = y.values.squeeze()\n",
    "\n",
    "    n_rows = X_arr.shape[0]\n",
    "    n_windows = n_rows // window_size\n",
    "    usable = n_windows * window_size\n",
    "    if usable < n_rows:\n",
    "        print(f\"Обрізаю {n_rows - usable} рядків до {usable} для {n_windows} вікон\")\n",
    "\n",
    "    X_trim = X_arr[:usable]\n",
    "    y_trim = y_arr[:usable]\n",
    "\n",
    "    X_windows = X_trim.reshape(n_windows, window_size, X_arr.shape[1])\n",
    "    y_last = y_trim.reshape(n_windows, window_size)[:, -1]\n",
    "    y_windows = to_categorical(y_last, num_classes)\n",
    "    return X_windows, y_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbd3f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "    window_size: int,\n",
    "    num_features: int,\n",
    "    num_classes: int,\n",
    "    params: Dict[str, Any]\n",
    ") -> Model:\n",
    "    \"\"\"\n",
    "    Будує 1D-CNN + BiLSTM модель з механізмом уваги на основі параметрів.\n",
    "\n",
    "    :param window_size: довжина вікна часових рядів\n",
    "    :param num_features: кількість ознак\n",
    "    :param num_classes: кількість класів для класифікації\n",
    "    :param params: словник з гіперпараметрами\n",
    "    :return: скомпільована модель Keras\n",
    "    \"\"\"\n",
    "    inp = Input(shape=(window_size, num_features))\n",
    "    x = inp\n",
    "\n",
    "    # Блок CNN\n",
    "    x = Conv1D(params['filters'], params['kernel_size'], padding='same',\n",
    "               kernel_initializer=params['kernel_initializer'])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv1D(params['filters'], params['kernel_size'] + 2, padding='same',\n",
    "               kernel_initializer=params['kernel_initializer'])(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = MaxPooling1D(params['pool_size'])(x)\n",
    "    x = Dropout(params['dropout_rate'])(x)\n",
    "\n",
    "    # Блок BiLSTM\n",
    "    for _ in range(params['lstm_layers']):\n",
    "        x = Bidirectional(\n",
    "            LSTM(params['lstm_units'], return_sequences=True,\n",
    "                 dropout=params['dropout_rate'],\n",
    "                 recurrent_dropout=params['recurrent_dropout'])\n",
    "        )(x)\n",
    "    x = Dropout(params['dropout_rate'])(x)\n",
    "\n",
    "    # Механізм уваги\n",
    "    attn = Dense(1, activation='tanh')(x)\n",
    "    attn = Softmax(axis=1)(attn)\n",
    "    context = Multiply()([x, attn])\n",
    "    context = Lambda(lambda z: K.sum(z, axis=1))(context)\n",
    "\n",
    "    # Голова класифікації\n",
    "    x = Dense(128, activation=params['activation'],\n",
    "              kernel_initializer=params['kernel_initializer'])(context)\n",
    "    x = Dropout(params['dropout_rate'])(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    optimizer_cls: Union[Type[tf.keras.optimizers.Optimizer], tf.keras.optimizers.Optimizer] = params['optimizer']\n",
    "    optimizer = optimizer_cls(learning_rate=params['optimizer__learning_rate'])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018fcddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: Model,\n",
    "    X_test: np.ndarray,\n",
    "    y_test: np.ndarray\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Обчислює набір метрик для тестового набору.\n",
    "    \"\"\"\n",
    "    y_prob = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    return {\n",
    "        'accuracy': np.mean(y_pred == y_true),\n",
    "        'balanced_accuracy': balanced_accuracy_score(y_true, y_pred),\n",
    "        'mcc': matthews_corrcoef(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_prob, multi_class='ovo', average='macro'),\n",
    "        'avg_precision': average_precision_score(y_true, y_prob, average='macro')\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc969e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a2f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search():\n",
    "    \"\"\"\n",
    "    Виконує перебір гіперпараметрів за PARAM_GRID,\n",
    "    навчає та оцінює модель, зберігає результати.\n",
    "    \"\"\"\n",
    "    # Завантаження даних\n",
    "    X_train_df = load_csv(DATA_DIR / 'x_train.csv',\n",
    "                           drop_cols=['Unnamed: 0', 'Init_Win_bytes_forward'])\n",
    "    y_train_df = load_csv(DATA_DIR / 'y_train.csv', drop_cols=['Unnamed: 0'])\n",
    "    X_val_df = load_csv(DATA_DIR / 'x_val.csv', drop_cols=['Unnamed: 0', 'Init_Win_bytes_forward'])\n",
    "    y_val_df = load_csv(DATA_DIR / 'y_val.csv', drop_cols=['Unnamed: 0'])\n",
    "    X_test_df = load_csv(DATA_DIR / 'x_test.csv', drop_cols=['Unnamed: 0', 'Init_Win_bytes_forward'])\n",
    "    y_test_df = load_csv(DATA_DIR / 'y_test.csv', drop_cols=['Unnamed: 0'])\n",
    "\n",
    "    # Підготовка вікон\n",
    "    X_train, y_train = prepare_windowed_data(X_train_df, y_train_df, WINDOW_SIZE, NUM_CLASSES)\n",
    "    X_val, y_val = prepare_windowed_data(X_val_df, y_val_df, WINDOW_SIZE, NUM_CLASSES)\n",
    "    X_test, y_test = prepare_windowed_data(X_test_df, y_test_df, WINDOW_SIZE, NUM_CLASSES)\n",
    "\n",
    "    results: List[Dict[str, Any]] = []\n",
    "\n",
    "    for params in ParameterGrid(PARAM_GRID):\n",
    "        print(f\"Навчання з параметрами: {params}\")\n",
    "        # Відділяємо аргументи для моделі\n",
    "        model_params = {k: v for k, v in params.items()\n",
    "                        if k not in ('batch_size', 'epochs')}\n",
    "        model = create_model(WINDOW_SIZE, NUM_FEATURES, NUM_CLASSES, model_params)\n",
    "\n",
    "        # Навчання\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            callbacks=CALLBACKS,\n",
    "            verbose=1\n",
    "        )\n",
    "        # Оцінка\n",
    "        metrics = evaluate_model(model, X_test, y_test)\n",
    "        # Збереження рядка результатів\n",
    "        row = {**params, **{\n",
    "            'test_accuracy': metrics['accuracy'],\n",
    "            'test_balanced_accuracy': metrics['balanced_accuracy'],\n",
    "            'test_mcc': metrics['mcc'],\n",
    "            'test_roc_auc': metrics['roc_auc'],\n",
    "            'test_avg_precision': metrics['avg_precision']\n",
    "        }}\n",
    "        results.append(row)\n",
    "        # Очищення сесії для звільнення пам'яті\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(RESULTS_PATH, index=False)\n",
    "    print(f\"Збережено результати у {RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_grid_search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
